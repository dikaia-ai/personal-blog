[{"content":"GitHub is a version control system that allows users to manage and host their projects. It provides built in functionality for tracking code changes, conduct code review, create dependency graphs and much more.\nInstall Git # ubuntu sudo apt install git # mac os w/brew package manager brew install git # windows w/chocolatey package manager choco install git # windows w/anaconda conda install -c anaconda git Create a New Repository Assuming you have already signed up for a GitHub account, you should see something similar to the image shown below. I have covered a few repo\u0026rsquo;s and accounts that are private but you should still be able to get a general idea of what the main landing page looks like on GitHub.\nTo create a new repo, select the New button in the upper left hand portion of the screen. This will take you to a new page where you can fill out the information about your new repo.\nOn this page, you start by entering a repo name. This repo name will be used to identify your repository and is what you will use when it is time to download or \u0026ldquo;clone\u0026rdquo; your repository. Next, you can select if you want the repository to be public or private. Private repositories will not be visible when people visit your public profile.\nYou can also choose to initialize a README, gitignore, or license at the same time you create your repository. The README is a markdown file that is rendered on the main page of your Git Repo. This file will typically contain instructions, citations, versioning information, etc. - basically anything you want other people to know, include it in your README.\nYou can also select to include a gitignore file - this file lists which files or folders to not track in your project directory. For example, if I had a virtual environment setup in my project called venv, I could list the venv folder in a gitignore which would prevent it from being uploaded to GitHub. Lastly, you can select the appropriate license to go along with your project. We are not going to go into licensing in this tutorial so I suggest checking out this page for which license to use. Reminder - these options are \u0026hellip; optional.\nCloning Your Repository Once you have created your Git Repo, you should see something similar to what is shown in the image below. As you can see, this page contains a lot of information but we will break it down to the core essentials to get up and running with GitHub.\nTo begin adding files, we first need to save this repository to our local machine. Note - you can upload files by using the Add file button, however I think it is important to get comfortable using the command line.\nOpen your respective terminal app and change to the directory where you want your repo to be saved.\n# Change directory to my \u0026#34;Documents\u0026#34; folder cd ~/Documents Now, clone your GitHub repo to this directory using the following command.\n# replace url with your repo\u0026#39;s url git clone https://github.com/kmcleste/git-tutorial.git If you are unsure of how to find this url, select the Code button on your GitHub repo page and you will be shown the link to download your project (see image below).\nOnce this is complete, you should see your repo folder appear in your directory. Now cd into the repo folder.\nAdding Files to Repository To begin adding files, you will first need files to add ðŸ˜„. So lets begin by creating a test file to upload. Here I am going to create a new file called test.py. GitHub is pretty language agnostic so it does not matter what type of file you want to upload - I\u0026rsquo;m just using python because that is what I\u0026rsquo;m familiar with.\n# create new test file touch test.py # edit test file nano test.py For this example, I use the built-in nano editor but you can use any IDE or text editor you like to create this file. Contrary to what many opinionated people will say online, just use whatever you are comfortable with.\nNow that we have a new file created, we need to prepare it to be sent to GitHub. For this, we must first add our changes/files. To do this, simply run:\n# you can either use the period (add all files) # or type a specific file path git add . We can check to make sure our changes have been added by returning the status of our git repo.\nNotice how the output shows that we have staged changes for our new file called test.py. At this point, if we changed our mind and no longer want to include these changes, we could revert the changes by restoring the staged file(s).\nLet\u0026rsquo;s assume for this demo that we are happy with the file we have created and want to keep the changes made.\nYou can now commit your changes to the repository by running:\ngit commit -m \u0026#34;created test.py\u0026#34; The -m \u0026quot;created test.py\u0026quot; is called a commit message and is required for committing changes to a repo. Always try to include an informative message that indicates what you changed or why you changed it.\nTo update these changes on the GitHub website, push your committed changes:\ngit push origin main Note - if git requests a username and password, please read the next section \u0026ldquo;Configuring Authentication\u0026rdquo;\nIn the above command, origin refers the directory we are going to push our changes. By default, git sets your origin to be the url you provided when you ran git clone. Next, main refers to the branch you would like to push your changes. Main is automatically set as the default branch for a new repository - if you see older tutorials, they may list master as the primary branch, just know these function as the same thing. Branches are useful for creating different versions or iterations of a project without having to over-write old editions.\nYou should now be able to see your new file as shown below.\nConfiguring Authentication When you push/pull to GitHub, you may be prompted for a username and passsword. GitHub uses personal access tokens to authenticate users - similar to how apple or google handle authentication with \u0026ldquo;app specific passwords\u0026rdquo;. To create a personal access token:\n Go to GitHub \u0026ndash;\u0026gt; Settings Select Developer Settings Under Personal access tokens, select Generate new token Give the token a short description Set the Expiration time Select the scope for the given token  I typically choose repo for personal projects   Click Generate token \u0026ndash;\u0026gt; do not close this page Back in your terminal, run the following:  # depending on your system, you will need to run either of these commands # this will save your access token the next time you are prompted for it git config --global credential.helper manager-core git config --global credential.help store Run your git push command again  When prompted, enter your username For password, copy / paste the personal access token we created in step 7  Since it\u0026rsquo;s a password, you will not see any text appear in your terminal but this is normal      If you would like to use SSH to connect to repositories, see my other post: Git SSH Integration\nTL;DR  Create new git repo git clone git add git commit git push  setup access token    Final Comments There are many more features included with git and GitHub that are not shown in this tutorial. Being efficient with git is an art of its own. For now, you should be able to create and add files to a new repository. Start playing around with making new projects and hosting them on GitHub; you will eventually find that you may need more functionality but this should at least give you a good starting point.\n","permalink":"https://kmclester.com/posts/github/first-git/","summary":"Create repository and make first commit","title":"Creating a GitHub Repo"},{"content":"Hugo is the foundation we will be using to create our blog website - it is the framework that this very website is built upon. If you are unfamiliar with Hugo, it is a static site generator. A static site is a website that does not connect to a backend server - ie, the website does not dynamically change and all of the elements are fixed in place at the time of render/compilation.\nThe core of Hugo is built around markdown files. We will see more detail on this later but for now just understand that Hugo uses these markdown files to render each page or post on our website.\nCreating a Hugo Project Note: The Hugo documentation goes into much more detail than I will be able to here. I am using a macOS system so I am unable to definitively explain the install process on other operating systems. Once you have the installation completed, all of the following steps will be identical, regardless of operating system. If you have questions, feel free to reach out using the contact page and I will do my best to respond.\nStep 1: Version Control It is highly recommended to use a version control system for keeping up with changes to your website and it is required if you would like to host your site on a service like Netlify. If you do not already know how to use GitHub, please read through my post on setting up your first repository\nStep 2: Installation brew install hugo To verify your install:\nhugo version Step 3: Create a New Site hugo new site my-blog This command will create a new site folder called my-blog in the directory from which you ran the script. For example, if we created a new website in the www folder, the file structure would be:\nðŸ“‚ www ðŸ“‚ my-blog ðŸ“‚ archetypes ðŸ“‚ content ðŸ“‚ layouts ðŸ“‚ themes ðŸ“‚ data ðŸ“‚ static ðŸ“„ config.toml ","permalink":"https://kmclester.com/posts/hugo/create-blog/","summary":"ðŸš§ UNDER CONSTRUCTION","title":"Creating a Personal Blog Site"},{"content":"You may be accustomed to using your Git project url (https) for cloning and pushing to your Git repo, however you can also use SSH. I\u0026rsquo;m not going to go into which method is better, I\u0026rsquo;ll just be showing you how it\u0026rsquo;s done.\nCreating SSH Key  First, we must check if an SSH key already exists. You can do so by running:  ssh-add -l If no key exists, run the following command:  # substituting email for the email you use with GitHub ssh-keygen -t rsa -b 4096 -C \u0026#34;kmcleste@uncc.edu\u0026#34; Press enter to accept the default file location Enter a Secure Passphrase Press Enter to complete key generation Display the contents of your Public Key  # this is the path for my default installation, yours may be different # refer to the path provided when creating your key cat ~/home/kyle/.ssh/id_rsa.pub Copy the contents of your Public Key  Add Key to GitHub  Login to your GitHub account Click your avatar and choose Settings Select SSH and GPG Keys from the settings list Click New SSH Key Enter a descriptive title in the title field Paste your public key into the Key field Finish by clicking Add SSH Key  SSH in Action Now when you set your origin or clone/push/pull, you will use the ssh link provided by GitHub; which will look something like this:\ngit clone git@github.com:kmcleste/git-tutorial.git Assuming you set a passphrase in the previous steps, you will be prompted for this phrase everytime you try to clone/push/pull.\n","permalink":"https://kmclester.com/posts/github/git-ssh/","summary":"Secure git repo connection with SSH","title":"GitHub SSH"},{"content":"OCTIS GitHub\nOCTIS or \u0026ldquo;Comparing and Optimizing Topic Models is Simple\u0026rdquo; was created by a team in Italy to assist with training, analyzing, and comparing topic models (Terragni et al. 2021). They intend for OCTIS to be used by researchers to aid in comparing models of interest; which are scored using benchmark datasets and well-known evalutation metrics. Assuming wide adoption, it would make comparing research teams results' much easier as everyone would be using the same testing methodology.\nWhat is Topic Modeling? If you have never heard of or worked with topic modeling, have no fear; the concept is pretty intuitive. The general premise behind topic models are that they are statistical methods that aim to extract the hidden topics underlying a collection of documents. Said differently, they allow us to get a \u0026ldquo;birds eye view\u0026rdquo; of a documents content. For example, if we were performing topic modeling on the linked research paper, the model may return \u0026ldquo;octis framework optimize evaluation hyperparameter\u0026rdquo;. As I mentioned, this gives us an idea of what the document is about without having to read the entire paper.\nA Brief History An early version of topic modeling was originally described in 1998 (Papadimitriou et al. 1998). Another was created by Thomas Hofmann in 1999 called probabilistic latent semantic analysis or \u0026ldquo;PLSA\u0026rdquo; (Hofmann 1999). Shortly thereafter, Latent Dirichlet allocation (LDA) was created as a generalization of PLSA - this is generally accepted as the most common topic model currently in use (Blei, Ng, and Jordan 2003).\nLDA is an unsupervised approach that allows us to find latent or \u0026ldquo;hidden\u0026rdquo; themes in a collection of documents. This process assumes each document is a \u0026ldquo;bag of words\u0026rdquo; and that each word/document falls into one of k topics. We\u0026rsquo;re able to use the following probabilities: P(topic t | document d) and P(word w | topic t) to surmise the appropriate topic associated with each document. LDA also uses Bayesian principles in the form of generating prior predictive probabilities and applying Bayesian updating to iteratively calculate posterior probabilities - once some threshold is met, the algorithm returns the list of topics and associated words.\nAs I mentioned, LDA is one of the most popular options and is great for what it is but it experiences one major pitfall \u0026ndash; context. LDA and topic models as a whole began to fall out of favor with scientists around 2012 due to the introduction of neural based approaches (Ruder 2021). These approaches include word embeddings (word2vec, glove, etc), sequence-to-sequence models, attention (transform) models, and pre-trained language models (BERT, Huggingface, etc). A nueral based approach allows models to account for the context in which a word is spoken/written - they can alter their vector representation based on surrounding words, part of speech, etc.\nFortunately, topic models have recently recieved a neural \u0026ldquo;facelift\u0026rdquo; as well. Several new methods such as Neural LDA, Embedded Topic Models (ETM), and Contextualized Topic Models (CTM) have all been developed within the last two to five years (Terragni et al. 2021). The team behind OCTIS hope to combine both modern and traditional techniques into a unified framework - such that researchers can compare the accuracy of models against a standardized baseline. The intention is not to determine which model is the all-around king of models, rather, it is to test which model would be the best for a given scenario. Neural approaches are all the rave right now but occassionally it is wise to brush off the traditional methods as they may be faster, more efficient, or achieve 95% of the desired response with minimal effort. It is also a good idea to understand the old way of doing things so you can better appreciate what newer methods have to offer.\ntl;dr LDA is great; people think neural nets are cool; new isn\u0026rsquo;t always better but sometimes it is; OCTIS wants to make comparing them easier; models are just tools\nLearning is a Process OCTIS follows the general framework shown below. These pipelines are setup for ease of use but also repeatability. Understanding this workflow is key to being successful with OCTIS.\nPre-processing First, we import a raw dataset and pass it to the pre-processing pipeline. This pipeline can convert all text to lowercase, remove punctuation, lemmatization, remove stop words (a, and, the, etc.), remove unfrequent and most frequent words based on a given threshold, and remove documents with less words than some threshold value. It is important to remember that just because a utility is included, does not mean you have to use it. Not every document requires the aforementioned operations and it\u0026rsquo;s up to the researchers discression to determine the best course of action.\nOCTIS includes several tests datasets:\n   Dataset Domain # Docs Avg # words in docs # Unique words     20 News-groups Forum posts 16309 48 1612   BBC News News 2225 150 3106   M10 Scientific Papers 8355 6 1696   DBLP Scientific Papers 54595 5 1513    Topic Modeling OCTIS includes a variety of off-the-shelf topic models, including both classical and neural approaches. The included models are:\n Latent Dirichlet Allocation (LDA) Non-negative Matrix Factorization (NMF) Latent Semantic Analysis (LSI) Hierarchical Dirichlet Process (HDP) Neural LDA Product-of-Experts LDA (ProdLDA) Embedded Topic Models (ETM) Contexualized Topic Models (CTM)  Topic models are effectively a black-box. They take a dataset as input and a set of hyperparameters and return the top-t topic words, the document-topic distributions, and the topic-word distribution in a specified format.\nEvaluation metrics The evaluation metrics can be used in two ways:\n An objective which is targeted by the Bayesian Optimization strategy A metric in which to monitor the behavior of a topic model while the model is optimized on a different objective  Performance of the topic model can be evaluated using the following metrics:\n Topic coherence metrics Topic significance metrics Diversity metrics Classification metrics  OCTIS provides 10 evaluation metrics directly from their web dashboard and then 13 additional metrics can be accessed through the python library.\nHyper-parameter Optimization If any of the available hyper-parameters are selected to be optimized (for a given evaluation metric), the Bayesian Optimization engine explores the search space to determine the optimal settings. These optimal settings are based on a desired threshold set for the selected evaluation metric. The team behind OCTIS realized that the performance estimated by these metrics can be subject to noise, so they decided the objective function should be computed as the median of n-model runs, using the same hyper-paramter configuration.\nIn this case, Bayesian Optimization is a sequential model-based optimization strategy for black-box functions (topic models). The general idea is to use all of the model\u0026rsquo;s configurations evaluated so far to best approximate the value of the selected performance metric and then select a new promising configuration to evaluate (Terragni et al. 2021).\n\u0026ldquo;The approximation is provided by a probabilistic surrogate model, which describes the prior belief over the objective function using the observed configurations. The next configuration to evaluate is selected through the optimization of an acquisition function, which leverages the uncertainty in the posterior to guide the exploration.\u0026rdquo; (Terragni et al. 2021)\n OCTIS in Action LDA Example # Import dependencies from octis.models.LDA import LDA from octis.dataset.dataset import Dataset from octis.evaluation_metrics.diversity_metrics import TopicDiversity from octis.evaluation_metrics.coherence_metrics import Coherence  # Define dataset dataset = Dataset() dataset.fetch_dataset(\u0026#34;20NewsGroup\u0026#34;)  # Create Model model = LDA(num_topics=20, alpha=0.1)  # Train the model using default partition choice output = model.train_model(dataset) print(*list(output.keys()), sep=\u0026#34;\\n\u0026#34;) # Print the output identifiers topic-word-matrix topics topic-document-matrix test-topic-document-matrix    # Return the generated topics [\u0026#39; \u0026#39;.join(x) for x in output[\u0026#39;topics\u0026#39;]] ['woman son church kill body wife people mother leave start', 'government state people law information group issue military make control', 'file image program version application include widget system window server', 'people make give sin day time man life love good', 'list print program port computer printer include work address color', 'people religion make thing belief time christian question point church', 'car good make price engine mile power buy water sell', 'encryption chip clipper key system government technology law year escrow', 'time phone people ground happen start make hear leave put', 'question drive monitor power system apple post newsgroup answer gay', 'game team win play year good player time season make', 'drive card disk run work system driver scsi make chip', 'drug test patient disease doctor medical study problem good card', 'make fire claim people evidence point reason post word case', 'window problem work mode run block bit switch button memory', 'armenian people turkish year genocide population jewish village greek war', 'key mail send number message post info call reply company', 'homosexual man sex homosexuality male sexual cap make pen show', 'gun law weapon people firearm car good death pay kill', 'space launch system cost mission satellite orbit solar make year']    # Initialize performance metric npmi = Coherence(texts=dataset.get_corpus(), topk=10, measure=\u0026#39;c_npmi\u0026#39;) # Initialize performance metric topic_diversity = TopicDiversity(topk=10)  # Retrieve metric scores topic_diversity_score = topic_diversity.score(output) print(f\u0026#39;Topic diversity: {str(topic_diversity_score)}\u0026#39;) npmi_score = npmi.score(output) print(f\u0026#39;Coherence: {str(npmi_score)}\u0026#39;) Topic diversity: 0.725   Coherence: 0.07167448455491789    NOTE: For a neural-based example, see the Google Colab notebook provided by OCTIS.\n Sources Blei, David M, Andrew Y Ng, and Michael I Jordan. 2003. \u0026ldquo;Latent Dirichlet Allocation.\u0026rdquo; Journal of Machine Learning Research 3 (Jan): 993\u0026ndash;1022.\n Hofmann, Thomas. 1999. \u0026ldquo;Probabilistic Latent Semantic Indexing.\u0026rdquo; In Proceedings of the 22nd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, 50\u0026ndash;57. SIGIR \u0026lsquo;99. New York, NY, USA: Association for Computing Machinery. https://doi.org/10.1145/312624.312649.\n Papadimitriou, Christos H., Hisao Tamaki, Prabhakar Raghavan, and Santosh Vempala. 1998. \u0026ldquo;Latent Semantic Indexing: A Probabilistic Analysis.\u0026rdquo; In Proceedings of the Seventeenth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems, 159\u0026ndash;68. PODS \u0026lsquo;98. New York, NY, USA: Association for Computing Machinery. https://doi.org/10.1145/275487.275505.\n Ruder, Sebastian. 2021. \u0026ldquo;A Review of the Recent History of Natural Language Processing.\u0026rdquo; Sebastian Ruder, Sebastian Ruder.\n Terragni, Silvia, Elisabetta Fersini, Bruno Giovanni Galuzzi, Pietro Tropeano, and Antonio Candelieri. 2021. \u0026ldquo;OCTIS: Comparing and Optimizing Topic Models Is Simple!\u0026rdquo; In Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: System Demonstrations, 263\u0026ndash;70. Online: Association for Computational Linguistics. https://doi.org/10.18653/v1/2021.eacl-demos.31.\n  ","permalink":"https://kmclester.com/posts/octis/octis/","summary":"Optimizing and Comparing Topic Models is Simple!","title":"Intro to OCTIS"},{"content":"Head to the Get Started page on Quarto\u0026rsquo;s website and download the latest version of Quarto for your operating system. You can verify your installation is working by running this command:\nquarto check install Hugo Integration Once you have verified your installation, you can head over to your project folder. Start by editing your site configuration file (config.toml) by adding the following parameters:\nignoreFiles = [ \u0026#34;\\\\.qmd$\u0026#34;, \u0026#34;\\\\.ipynb$\u0026#34; ] [markup.goldmark.renderer] unsafe = true Creating Quarto documents   Create a directiry within content that will hold your Quarto article\n  Add your article as a .qmd file. So you might name it something like \u0026ldquo;tutorial.qmd\u0026rdquo;. This will create \u0026ldquo;tutorial.md\u0026rdquo; when rendered which is then displayed by Hugo.\n  Add your Hugo front matter and then specify format: hugo and any other Quarto options. Here\u0026rsquo;s an example front matter:\n  --- title: How to Quarto date: \u0026#34;2022-02-08\u0026#34; format: hugo author: Kyle McLester description: Adding Quarto to Existing Hugo Project --- To render Quarto markdown to regular markdown, use the following:  quarto render $PATH_TO_FILE/$FILE.qmd ","permalink":"https://kmclester.com/posts/quarto/how-to-quarto/","summary":"Integrate Quarto to your Hugo website","title":"How to Quarto"},{"content":"","permalink":"https://kmclester.com/posts/rasa/create-chatbot/","summary":"ðŸš§  UNDER CONSTRUCTION","title":"Getting Started with Rasa"},{"content":"","permalink":"https://kmclester.com/posts/gcp/gcp-vm/","summary":"ðŸš§  UNDER CONSTRUCTION","title":"Google Cloud Platform"},{"content":" form{ background: rgba(27,31,34,0.80); width: 640px; margin: 50px auto; max-width: 97%; border-radius: 4px; padding: 55px 30px; } form .title h2{ letter-spacing: 6px; display: inline-block; padding: 8px; margin-bottom: 32px; } form{ border: 1px solid white; } form .half{ display: flex; justify-content: space-between; } form .half .item{ display: flex; flex-direction: column; margin-bottom: 24px; width: 48%; } form label{ display: block; font-size: 13px; letter-spacing: 3.5px; margin-bottom: 16px; } form .half .item input{ border-radius: 4px; border: 1px solid white; outline: 0; padding: 16px; width: 100%; height: 44px; background: transparent; font-size: 17px; } form .full{ margin-bottom: 24px; } form .full textarea{ background: transparent; border-radius: 4px; border: 1px solid white; outline: 0; padding: 12px 16px; width: 100%; height: 200px; font-size: 17px; } form .action{ margin-bottom: 32px; } form .action input{ background: transparent; border-radius: 4px; border: 1px solid white; cursor: pointer; font-size: 13px; font-weight: 600; height: 44px; letter-spacing: 3px; outline: 0; padding: 0 20px 0 22px; margin-right: 10px; } form .action input[type=\"submit\"]{ background: white; color: black; } form .half .item input:focus, form .full textarea:focus, form .action input[type=\"reset\"]:hover{ background: rgba(255,255,255,0.075); } form .action input[type=\"reset\"]{ color: white; } @media (max-width: 480px){ form .half{ flex-direction: column; } form .half .item{ width: 100%; } form .action{ display: flex; flex-direction: column; } form .action input{ margin-bottom: 10px; width: 100%; } }   Let's Connect!  NAME  EMAIL   MESSAGE      ","permalink":"https://kmclester.com/contact/","summary":"Let\u0026rsquo;s Connect!","title":"Contact"}]