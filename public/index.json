[{"content":"The Rasa Ephemeral (REI) method of installation grants users access to the Rasa X feature. Rasa X is a web interface that allows developers to rapidly build, test, and push chat assistants to a Git repository. Within Rasa X you can label entities, flag conversations for review, share your chatbot with testers and more.\nFor this demonstration I will be deploying REI to a Google Cloud Platform instance - if you do not already know how to create a GCP instance, check out this post first: Getting Start with GCP \nGetting Connected First you must SSH into your GCP instance. This can either be done through the GCP Compute Engine instances list, or you can connect using GCloud CLI tools with the following command:\ngcloud config set project $PROJECT_NAME gcloud compute ssh $USER_NAME@$INSTANCE_NAME Download and Install REI Run the following command to download the REI installation script and execute the script:\ncurl -O https://rei.rasa.com/rei.sh \u0026amp;\u0026amp; bash rei.sh -y If you\u0026rsquo;re using a fresh vm instances, the script will start by installing docker - once this is complete, you will be prompted to reboot. You can reboot the system from the CLI with:\nsudo reboot Once you have rebooted, run the installation script again:\nbash ./rei.sh -y Create Values Config File To configure the rasactl cluster (based on kubernetes), create a file called values.yml\ntouch values.yml In the this file, add the following information:\nrasa: versions: rasaProduction: enabled: true rasaWorker: enabled: true # if you are using a custom action image, include the following: app: name: \u0026#34;\u0026lt;name of your action server image\u0026gt;\u0026#34; tag: \u0026#34;\u0026lt;tag of your image\u0026gt;\u0026#34; Starting Rasa Instance Using rasactl, create a new instance and point to the values file we just created:\nrasactl start $INSTANCE_NAME --values-file ~/values.yml If this is the first instance you\u0026rsquo;re creating, this will likely take several minutes to deploy.\n","permalink":"https://kmclester.com/posts/rasa/rei/","summary":"üöß UNDER CONSTRUCTION - Use the Rasa Ephemeral Installer to deploy to a Google Cloud server; gain access to useful features like Rasa X and GitHub integration","title":"Rasa Ephemeral Installer"},{"content":"Rasa  is an open source platform that allows you to create enterprise-level chat assistants. You may have experience with simple rule-based dialogue systems, however; Rasa takes it one step further by using NLP and NLU to understand the context in which user utterances are provided, and execute some function based on this given input.\nThe theory behind why you would want to create an automated chatbot vs speaking to a live agent is an entirely different discussion\u0026hellip;there are definitely many opinions on this.\nIn this short post, I will take you through creating your first Rasa project and give a brief explanation of the different parts that make Rasa function.\nFor more detailed information, I suggest checking out Rasa\u0026rsquo;s YouTube channel  and documentation .\nPreparation   Create a new project folder and open the directory\nmkdir $PROJECT_FOLDER cd $PROJECT_FOLDER   Create and activate a new virtual environment\nvirtualenv $ENV_NAME source $ENV_NAME/bin/activate For more info, see related post: Python Virtual Environments \n  Create git repository in project folder and add your virtual environment to .gitignore (optional)\n  Installing Rasa Dependencies   Install Rasa Open Source\npython3 -m pip install rasa   Confirm Installation\nrasa --version   If you have any trouble with install, check here for possible solutions When I first tried using Rasa, I ran into several errors pertaining to ssl, xml, developer versions, and requests. I believe these are all fixed in the latest version of Rasa (3.0.8), but just in case, these are some of the things that worked for me:\n  Installing/updating packages with errors\n# Linux sudo apt-get install pkg-config libssl-dev libffi-dev python3-dev libxml2-dev libxmlsec1-dev libxmlsec1-openssl # MacOS brew install openssl brew install libffi python3 -m pip install lxml brew install libxmlsec1   This should only apply to those using Rasa X but as of the time of writing this you need requests version 2.25.0\npython3 -m pip install requests==2.25.0   Let me know if you are unable to get it working and I will try to assist.\n\nCreating First Rasa Project   Within your root project directory, run:\nrasa init  Enter the path where the project will be created; the default is the current directory  If the directory is not empty, the system will ask if you would like to continue. If you type \u0026lsquo;y\u0026rsquo; or \u0026lsquo;n\u0026rsquo;, it will automatically move to the next step without asking for confirmation.   Do you want to train an initial model? I suggest selecting \u0026lsquo;no\u0026rsquo; for the time being. We will train a model in later steps.  This function will create a basic Rasa project using the Mood Bot example \u0026ndash; think of this like a Hello World project.\n  Below is an example of the folder structure and contents you should see after you have initialized your project. Expalanations of each file will be listed in later steps.\n(venv) ‚ûú kyle@ubuntu~$ tree -I venv . ‚îú‚îÄ‚îÄ actions ‚îÇ¬†‚îú‚îÄ‚îÄ __init__.py ‚îÇ¬†‚îî‚îÄ‚îÄ actions.py ‚îú‚îÄ‚îÄ config.yml ‚îú‚îÄ‚îÄ credentials.yml ‚îú‚îÄ‚îÄ data ‚îÇ¬†‚îú‚îÄ‚îÄ nlu.yml ‚îÇ¬†‚îú‚îÄ‚îÄ rules.yml ‚îÇ¬†‚îî‚îÄ‚îÄ stories.yml ‚îú‚îÄ‚îÄ domain.yml ‚îú‚îÄ‚îÄ endpoints.yml ‚îî‚îÄ‚îÄ tests ‚îî‚îÄ‚îÄ test_stories.yml   Training a Model Rasa makes it very easy to begin training a model, simply run:\nrasa train Interacting With Your Chatbot There are several ways to speak to your now-trained chatbot. The most basic of these is through rasa shell:\nrasa shell -m models The -m models in the above code is explicitly telling Rasa to check our models directory for a trained language model \u0026ndash; \u0026lsquo;models\u0026rsquo; is the default folder so this is not required but it can be useful to state in some cases.\nYou should see something similar to the image below show up in your terminal. Now you can begin talking to your chatbot!\nYou can also run Rasa in a server configuration using the following command:\nrasa run -m models --enable-api --cors \u0026#34;*\u0026#34; This will allow you to make API calls to your Rasa server, which returns a formatted json object as a response. This is most likely the option you will use if you decide to connect your chatbot to any sort of front end components like a chat widget. There are several other methods for deploying your chatbot but I will talk about those in Part 2.\nSome useful runtime options  -p $PORT, --port $PORT  Default rasa server port = 5005   --cors ‚Äú*‚Äù  Whitelist all origins using * Default = None   --enable-api  Default = False Starts a web server API in addition to the input channel   --ssl-certificate $SSL_CERT_FILE_PATH  Default = None Creates a TLS secured server   --ssl-keyfile $SSL_KEY_FILE_PATH  Default = None Creates a TLS secured server   --ssl-password $SSL_PASSWORD  Default = None If your ssl-keyfile is protected by a password    \nConfiguration Rasa uses yaml files for configuring settings, pipelines, etc. If no configuration is provided, the default configuration is loaded:\n# The config recipe. # https://rasa.com/docs/rasa/model-configuration/ recipe: default.v1 # Configuration for Rasa NLU. # https://rasa.com/docs/rasa/nlu/components/ language: en pipeline: # # No configuration for the NLU pipeline was provided. The following default pipeline was used to train your model. # # If you\u0026#39;d like to customize it, uncomment and adjust the pipeline. # # See https://rasa.com/docs/rasa/tuning-your-model for more information. - name: WhitespaceTokenizer - name: RegexFeaturizer - name: LexicalSyntacticFeaturizer - name: CountVectorsFeaturizer - name: CountVectorsFeaturizer analyzer: char_wb min_ngram: 1 max_ngram: 4 - name: DIETClassifier epochs: 100 constrain_similarities: true - name: EntitySynonymMapper - name: ResponseSelector epochs: 100 constrain_similarities: true - name: FallbackClassifier threshold: 0.3 ambiguity_threshold: 0.1 # Configuration for Rasa Core. # https://rasa.com/docs/rasa/core/policies/ policies: # # No configuration for policies was provided. The following default policies were used to train your model. # # If you\u0026#39;d like to customize them, uncomment and adjust the policies. # # See https://rasa.com/docs/rasa/policies for more information. - name: MemoizationPolicy - name: RulePolicy - name: UnexpecTEDIntentPolicy max_history: 5 epochs: 100 - name: TEDPolicy max_history: 5 epochs: 100 constrain_similarities: true When you are first starting out, the default configuration is usually sufficient for getting decent results. Of course these settings can be tinkered with and fine-tuned but its not absolutely necessary out of the box - which is nice. For more information on setting up a custom configuration, I suggest checking out this page  from Rasa.\nDomain The domain.yml file is used to define the \u0026ldquo;universe in which your assistant operates.\u0026rdquo; It specifies intents, entities, slots, responses, forms, and actions your bot should know about.\nHere\u0026rsquo;s the example domain.yml file that comes with the default Mood Bot:\nversion: \u0026#34;3.0\u0026#34; intents: - greet - goodbye - affirm - deny - mood_great - mood_unhappy - bot_challenge responses: utter_greet: - text: \u0026#34;Hey! How are you?\u0026#34; utter_cheer_up: - text: \u0026#34;Here is something to cheer you up:\u0026#34; image: \u0026#34;https://i.imgur.com/nGF1K8f.jpg\u0026#34; utter_did_that_help: - text: \u0026#34;Did that help you?\u0026#34; utter_happy: - text: \u0026#34;Great, carry on!\u0026#34; utter_goodbye: - text: \u0026#34;Bye\u0026#34; utter_iamabot: - text: \u0026#34;I am a bot, powered by Rasa.\u0026#34; session_config: session_expiration_time: 60 carry_over_slots_to_new_session: true For more information, check out Rasa\u0026rsquo;s domain documentation .\nTraining Data There are a series of different training data that Rasa uses to make a well-rounded chatbot. This data is usually stored in the \u0026hellip; you guessed it, data folder. It consists of NLU data, Stories, and Rules.\nThe NLU data provides examples of user utterances for a given intent (see code below for example). This data is what helps the model associate certain words and phrases with different actions or responses.\nRules are used to train the chatbots dialogue management model. These Rules describe short pieces of conversations that should always follow the same path (see code below).\nStories are similar to rules but are not set in stone, so to speak. Stories allow the assistant to generalize unseen conversation paths (again, code ‚¨áÔ∏è).\nversion: \u0026#34;3.0\u0026#34; nlu: - intent: greet examples: |- Hey - Hi - hey there [Sara](name) - intent: faq/language examples: |- What language do you speak? - Do you only handle english? stories: - story: greet and faq steps: - intent: greet - action: utter_greet - intent: faq - action: utter_faq rules: - rule: Greet user steps: - intent: greet - action: utter_greet Intents \u0026amp; Entities Intents and Entities are something you will work with very often in the Rasa ecosystem. Along with slots (these will be discussed in another post), intents and entities are largely what control conversation with your chat assistant.\nIntents  are nearly as they sound - they are what the user intends to do or convey. For example, if someone says \u0026lsquo;hello\u0026rsquo; then we could classify the intent as \u0026lsquo;greeting\u0026rsquo;; or if the assistant received \u0026lsquo;are you a bot\u0026rsquo; then the intent would be bot_challenge. You can see these intents listed in your NLU, Rules, Stories, and Domain files.\nEntities  are structured pieces of information inside a user message. They could be people, places, things, etc. - basically anything that can be extracted from a message and either used in a response or passed on to an action.\nClosing This should at least get you started and give you a base-level understanding of Rasa and its components. There will likely be more parts to follow - my goal is to cover nearly all of Rasa\u0026rsquo;s documentation in the coming weeks.\nIn the mean time, if you have any questions or concerns, please reach out through the contact page .\n","permalink":"https://kmclester.com/posts/rasa/create-chatbot/","summary":"Creating your first conversational ai assistant using Rasa Open Source","title":"Getting Started with Rasa - Part 1"},{"content":"Have you ever gone to follow a python tutorial and realized that nothing seems to work - or that you get seemingly endless package errors? This is where virtual environments can come in handy.\nVirtual environments (venv or virtualenv) allow us to create a sandbox for our python environment. We can install, update, upgrade packages in these environments without impacting the rest of the packages already installed on our system.\nThis also aids the function of reproducibility \u0026ndash; say you have a project that uses a package which is dependent on python2.7 but your system is running python3.8, what do you do? Instead of creating aliases or weird path variables, you can simply use a virtual environment and load whatever version of python you need. This goes for packages as well.\nInstalling Virtualenv There are several virtual environment tools but I will be showing you virtualenv. To install this on Linux or MacOS, run the following:\n# Linux sudo apt-get install virtualenv #MacOS brew install virtualenv You can confirm this was installed by entering:\nwhich virtualenv Creating a Virtual Environment Change to your project directory and run the following:\ncd my-project/ virtualenv venv The above code will create a virtualenv called venv. This will usually appear as a new folder in your project directory with the same name.\nIf you would like your virtual environment to inherit globally installed packages, you can run:\nvirtualenv venv --system-site-packages Activate Your Environment You may have noticed this new venv folder appear but you are not able to access your packages - this is because you have to activate your virtual environment. This can be done by running the following:\nsource venv/bin/activate You will know venv is active when your terminal shows the environment name:\n(venv) kyle@ubuntu:~$ The above will run the activation script from within the venv folder. Keep in mind that if you are not running this from your root project directory, that you will need to replace the word venv with your entire directory path.\nNow you are free to pip install packages and they will be saved in the venv environment.\nReproducibility Tip Once you have finished installing all of your packages, to create a full list of all the package and version information, run the following:\npip freeze \u0026gt; requirements.txt This function will create a file with the structure package_name==version:\nscipy==1.8.0 sentence-transformers==2.2.0 sentencepiece==0.1.96 seqeval==1.2.2 smmap==5.0.0 sniffio==1.2.0 spacy==3.2.2 spacy-legacy==3.0.8 spacy-loggers==1.0.1 SPARQLWrapper==1.8.5 SQLAlchemy==1.4.31 SQLAlchemy-Utils==0.38.2 sqlparse==0.4.2 You can then reinstall these packages using the requirements.txt file - or send it to a friend that wants to recreate your project. This can be done by running:\npython3 -m pip install -r requirements.txt  \nDeactivate your Environment When you are finished using the environment, you can deactivate it by running:\ndeactivate TL;DR  To install -\u0026gt; python3 -m pip install virtualenv To create -\u0026gt; virtualenv venv To activate -\u0026gt; source venv/bin/activate To deactivate -\u0026gt; deactivate  For further reading, I would suggest looking at this post from Peter Baumgartner  on creating python packages.\nClosing Thanks for reading. Please reach out through the contact page  if you have any questions or concerns - I really appreciate feedback. Also, share this with anyone who might find it useful!\n","permalink":"https://kmclester.com/posts/python/venv/","summary":"Create virtual environments for code reproducibility and easy sandboxing of python packages","title":"Python Virtual Environments"},{"content":"Hugo  is the foundation we will be using to create our blog website - it is also the framework that this website is built upon. If you are unfamiliar with Hugo, it is a static site generator. A static site is a website that does not connect to a backend server - ie, the website does not dynamically change and all of the elements are fixed in place at the time of render/compilation.\nThe core of Hugo is built around markdown files. We will see more detail on this later but for now just understand that Hugo uses these markdown files to render each page or post on our website.\nCreating a Hugo Project Note: The Hugo documentation  goes into much more detail than I will be able to here. I am using a macOS system so I am unable to definitively explain the install process on other operating systems. Once you have the installation completed, all of the following steps will be identical, regardless of operating system. If you have questions, feel free to reach out using the contact page  and I will do my best to respond.\nStep 1: Version Control It is highly recommended to use a version control system for keeping up with changes to your website and it is required if you would like to host your site on a service like Netlify . If you do not already know how to use GitHub, please read through my post on setting up your first repository .\nStep 2: Installation Run the installation command below. Remember - this is for macOS, so your command may differ.\nbrew install hugo To verify your installation, run the following:\nhugo version output:\n‚ûú hugo git:(main) ‚úó hugo version hugo v0.92.1+extended darwin/amd64 BuildDate=unknown Step 3: Create a New Site hugo new site my-blog -f yml # note: -f allows you to choose the file extension of your config file # the default is toml but I prefer yaml This command will create a new site folder called my-blog in the directory from which you ran the script. For example, if we created a new website in the www folder, the file structure would be:\nüìÇ www üìÇ my-blog üìÇ archetypes üìÇ content üìÇ layouts üìÇ themes üìÇ data üìÇ static üìÑ config.yml Step 4: Picking a Theme Something to note is that Hugo does not come with a theme out of the box. So, before you get started on creating the content of your pages, you will need to head to https://themes.gohugo.io/  and choose a theme that fits your site.\nI am using the PaperMod theme , created by Aditya Telange . For the sake of this demo, this is the theme that we will be using as it has a variety of features (search, categories, tags, etc) and it is pretty easy to get working.\n  Start by cloning the theme\u0026rsquo;s GitHub repository to your themes folder. This can be done a variety of ways but I prefer using GitHub\u0026rsquo;s submodule feature - think of it like nested repositories.\ngit submodule add https://github.com/adityatelange/hugo-PaperMod.git themes/PaperMod --depth=1 git submodule update --init --recursive # needed when you reclone your repo (submodules may not get cloned automatically) Once you have added the submodule, you should now see a new entry has been appended to your .gitmodules file and your themes folder now looks something like this:\nüìÇ themes üìÇ PaperMod üìÇ .github üìÇ assets üìÇ i18n üìÇ images üìÇ layouts üìÑ go.mod üìÑ LICENSE üìÑ README.md If you ever need to update the theme, run:\ngit submodule update --remote --merge   Next, we must alter the sites config.yml to use this new theme. The config file allows us to take advantage of the features that come bundled with the theme - and by setting certain variables, we can activate or modify these features. Below is an example of how I have my config setup but this is not the only way to do it, as you may need more or less features than I do. I strongly suggest checking if your theme has an example config file on the GitHub page that you downloaded the theme from.\n This is going to be a lot of text - skip to next step ‚¨áÔ∏è     baseURL: \u0026#34;https://kmclester.com/\u0026#34; # NOTE: include only if you have a custom domain title: My Blog paginate: 5 theme: PaperMod enableInlineShortcodes: true enableRobotsTXT: true buildDrafts: false buildFuture: false buildExpired: false enableEmoji: true googleAnalytics: G-06XXXXXXS minify: disableXML: true minifyOutput: true languages: en: languageName: \u0026#34;English\u0026#34; weight: 1 menu: main: - name: Archive url: archives weight: 5 - name: Search url: search/ weight: 10 - name: Tags url: tags/ weight: 10 - name: Categories url: categories/ weight: 10 outputs: home: - HTML - RSS - JSON params: env: production description: \u0026#34;Personal blog\u0026#34; author: Kyle McLester defaultTheme: auto ShowShareButtons: true ShowReadingTime: true displayFullLangName: true ShowPostNavLinks: true ShowBreadCrumbs: true ShowCodeCopyButtons: true ShowToc: true homeInfoParams: Title: \u0026#34;Welcome!\u0026#34; Content: \u0026gt;This website is going to act as a dumping ground for things I\u0026#39;m learning or working on. Feel free to take a peek socialIcons: - name: github url: \u0026#34;https://github.com/kmcleste\u0026#34; - name: RsS url: \u0026#34;index.xml\u0026#34; editPost: URL: \u0026#34;https://github.com/kmcleste/personal-blog/tree/main/content\u0026#34; Text: \u0026#34;Suggest Changes\u0026#34; appendFilePath: true analytics: google: SiteVerificationTag: \u0026#34;G-06XXXXXXS\u0026#34; taxonomies: category: categories tag: tags series: series markup: goldmark: renderer: unsafe: true privacy: vimeo: disabled: false simple: true twitter: disabled: false enableDNT: true simple: true instagram: disabled: false simple: true youtube: disabled: false privacyEnhanced: true services: instagram: disableInlineCSS: true twitter: disableInlineCSS: true Serve Hugo Site Locally To view the site on your local machine, simply run:\nhugo serve Open http://localhost:1313 in your browser, and you should be able to see the site live! Most themes come with default posts that can provide you with more information on how to use Hugo, the theme you selected, etc. - I would strongly recommend at least reading through some of these pages before creating your own content.\nCreating Content This is great but how do we actually make any webpages? The main folder that you will be working in is the content folder - this is where all of the pages/posts on your website will be kept.\nOpen the project directory in your favorite text editor or IDE - I\u0026rsquo;m using VS Code for this project. Now, you can open any file in the /content/posts directory to begin editing files. Every time you save, the website will automatically update with the new content.\nWith this in mind, you can begin creating your own webpages.\nFeel free to delete the included posts and begin making your own. Just remember, we are using markdown so you will need to create a new file with the .md file extension. Once you\u0026rsquo;ve created your file, you will need to set the pages \u0026amp;ldquo;front matter\u0026amp;rdquo; . The front matter is what allows you to attach meta data to your posts, as well as alter the configuration of a page. This is going to vary from theme to theme but I tend to use this for my pages:\n--- author: Kyle McLester date: 2022-02-21 format: hugo title: Creating a Personal Blog Site categories: - Web Development tags: - hugo - blog - personal website - markdown - netlify summary: Creating Your First Hugo Site --- Note - the three dashes above and below the front matter are formatted for yaml code. Which symbol to use depends on the format of your config file. If you are using toml, you would use +++ and json uses { }.\nThe front matter should be followed by a single new line and then your content. Checkout my github of this page  to see further example of how to format your markdown file(s).\nHosting with Netlify Incase you haven\u0026rsquo;t done so already, create a git repo for this project. As a quick refresher, feel free to follow the steps below:\n Go to GitHub and create a new repo In your root project directory, run git init Now add all of your files/changes by running git add . Commit your changes: git commit -m \u0026quot;Initial commit\u0026quot; Set branch to main: git branch -M main Add remote origin: git remote add origin \u0026lt;GIT_REPO_URL\u0026gt; Push changes to remote repo: git push origin main  Now head on over to Netlify  and create an accout/login.\nOnce you have logged in, you should be greeted with a dashboard with the option Add new site. Select this and follow the instructions:\n Add new site -\u0026gt; Import an existing project  You will be presented with three options: GitHub, GitLab, or BitBucket. Select GitHub  Next, you must authorize Netlify to grant access to your Git repositories. You can either grant access for all repositories or select a specific repo (ie your blog repo) Netlify will automatically recognize your project as a Hugo repo. I suggest keeping the options set to their defaults for now (see below)  Select deploy and wait for Netlify to build your website Once the build and deploy is completed, you should be able to access the link shown in your main site overview page  Now every time you commit new changes to your Git repo, Netlify will automatically build and redeploy with the latest updates!  Closing Congrats on making it this far. If you have any questions or concerns, please feel free to reach out using the contact page . Please share with anyone that might find this useful!!\n","permalink":"https://kmclester.com/posts/hugo/create-blog/","summary":"Create Your First Hugo Site with Netlify","title":"Creating a Personal Blog Site"},{"content":"Creating a cloud-based platform doesn\u0026rsquo;t have to be difficult. Google\u0026rsquo;s Cloud Platform (GCP) has created a variety of tools and services that allow users to quickly get up and running hosting their own apps, servers, and more. I am going to walk you through the process of creating a cloud-based virtual machine and connecting via SSH.\nAccessing GCP Creating an account with GCP is as simple as logging in with your gmail account. If you do not have a gmail account, you will have to create one to continue - use this link  to create yours now.\nNow, head to the Google Cloud Platform  and sign in  .\nOnce you have logged in, you will be taken to the main landing page. From here, click Go to console:\nCreating a Project If you have never created a project before, you will likely be presented with this window, select NEW PROJECT:\nFill in the proper details for your project and click CREATE. If you do not have an organization, select No Organization.\n NOTE - you will have to link a billing account if you wish to use the services going forward, however you do receive a free $300 credit when you sign up for the 90-day free trial. If you do not upgrade to the paid account, you will not be charged when your free credit\u0026rsquo;s run out. You will have 30 days to upgrade to a paid account or your resources will be lost. For more information on Google\u0026rsquo;s billing rules and procedures, visit https://cloud.google.com/free/docs/gcp-free-tier.\n    It will take a few minutes for your project to initialize but once it does, you will be taken to the GCP Project Dashboard.\nIf you are not taken to the dashboard or if you have multiple projects, you can always select your project using the drop-down in the top left.\nCompute Engine and Virtual Machines To begin creating a virtual machine (cloud server), you will have enable the Compute Engine. This is done by selecting the three-lines (hamburger icon) next to the GCP logo to open your Navigation Menu. Now select the Compute Engine option. You can pin this option for quick access in the future by hovering over the item and selecting the pin icon.\nNext, enable the compupte engine service by selecting ENABLE. This may take a few minutes:\nOnce the service is enabled, you will be brought to the Compute Engine dashboard. Here you will find a list of your running vm\u0026rsquo;s and a variety of management options. Feel free to explore these options but once you\u0026rsquo;re ready, select CREATE INSTANCE.\nFor this demo, we will create a vm with the following specifications:\nTo change your boot disk and OS properties, select CHANGE and choose the most appropriate options for your project. I am using Ubuntu 20.04 LTS with 50gb of storage for this demo. Whenever you are done selecting your options, click CREATE. This may take a few minutes. Once the initialization is complete, you will see your active vm in the VM Instances list on the Compute Engine dashboard.\nConnecting to Your Instance From the Compute Engine dashboard, find your running vm instance and click SSH under the Connect column. This will automatically transfer the necessary authentication keys to the vm instance. Once the connection is ready, you will see a terminal window that is now connected to your vm.\nAs with most OS installs, it is usually a good idea to update and upgrade once everything is up and running. To do so, run the following commands in your ssh terminal:\nsudo apt update sudo apt upgrade You can now use your vm instance as a normal server/computer via the terminal. You can also install the GCloud CLI  tools to connect using your computers default terminal app.\nRemoving VM Instance If you\u0026rsquo;ve decided you no longer need your vm, you first need to stop the vm via the Compute Engine dashboard. This is done by clicking the three vertical dots in the instances list, and selecting stop. As with the other operations, this will take a minute.\nOnce the instance is stopped, you can now delete the vm through the same menu we used to stop it.\nRemoving GCP Project If you need to delete your project, head back to the project dashboard by clicking the Google Cloud Platform logo in the upper left of the screen. From here, select Go to project settings.\nNow select SHUT DOWN from the top options bar. In the resulting window type your project ID and click SHUT DOWN. This will stop all billing, revoke access to the project, and delete all resources. You have 30 days to attempt to recover this process if it was done accidentally.\nClosing If you have any questions or concerns, please feel free to reach out using the contact page . Please share with anyone that might find this useful!!\n","permalink":"https://kmclester.com/posts/gcp/gcp-vm/","summary":"Create a GCP Virtual Machine for Web or App Hosting","title":"Google Cloud Platform"},{"content":"GitHub is a version control system that allows users to manage and host their projects. It provides built in functionality for tracking code changes, conduct code review, create dependency graphs and much more.\nInstall Git # ubuntu sudo apt install git # mac os w/brew package manager brew install git # windows w/chocolatey package manager choco install git # windows w/anaconda conda install -c anaconda git Create a New Repository Assuming you have already signed up for a GitHub account, you should see something similar to the image shown below. I have covered a few repo\u0026rsquo;s and accounts that are private but you should still be able to get a general idea of what the main landing page looks like on GitHub.\nTo create a new repo, select the New button in the upper left hand portion of the screen. This will take you to a new page where you can fill out the information about your new repo.\nOn this page, you start by entering a repo name. This repo name will be used to identify your repository and is what you will use when it is time to download or \u0026ldquo;clone\u0026rdquo; your repository. Next, you can select if you want the repository to be public or private. Private repositories will not be visible when people visit your public profile.\nYou can also choose to initialize a README, gitignore, or license at the same time you create your repository. The README is a markdown file that is rendered on the main page of your Git Repo. This file will typically contain instructions, citations, versioning information, etc. - basically anything you want other people to know, include it in your README.\nYou can also select to include a gitignore file - this file lists which files or folders to not track in your project directory. For example, if I had a virtual environment setup in my project called venv, I could list the venv folder in a gitignore which would prevent it from being uploaded to GitHub. Lastly, you can select the appropriate license to go along with your project. We are not going to go into licensing in this tutorial so I suggest checking out this page  for which license to use. Reminder - these options are \u0026hellip; optional.\nCloning Your Repository Once you have created your Git Repo, you should see something similar to what is shown in the image below. As you can see, this page contains a lot of information but we will break it down to the core essentials to get up and running with GitHub.\nTo begin adding files, we first need to save this repository to our local machine. Note - you can upload files by using the Add file button, however I think it is important to get comfortable using the command line.\nOpen your respective terminal app and change to the directory where you want your repo to be saved.\n# Change directory to my \u0026#34;Documents\u0026#34; folder cd ~/Documents Now, clone your GitHub repo to this directory using the following command.\n# replace url with your repo\u0026#39;s url git clone https://github.com/kmcleste/git-tutorial.git If you are unsure of how to find this url, select the Code button on your GitHub repo page and you will be shown the link to download your project (see image below).\nOnce this is complete, you should see your repo folder appear in your directory. Now cd into the repo folder.\nAdding Files to Repository To begin adding files, you will first need files to add üòÑ. So lets begin by creating a test file to upload. Here I am going to create a new file called test.py. GitHub is pretty language agnostic so it does not matter what type of file you want to upload - I\u0026rsquo;m just using python because that is what I\u0026rsquo;m familiar with.\n# create new test file touch test.py # edit test file nano test.py For this example, I use the built-in nano editor but you can use any IDE or text editor you like to create this file. Contrary to what many opinionated people will say online, just use whatever you are comfortable with.\nNow that we have a new file created, we need to prepare it to be sent to GitHub. For this, we must first add our changes/files. To do this, simply run:\n# you can either use the period (add all files) # or type a specific file path git add . We can check to make sure our changes have been added by returning the status of our git repo.\nNotice how the output shows that we have staged changes for our new file called test.py. At this point, if we changed our mind and no longer want to include these changes, we could revert the changes by restoring the staged file(s).\nLet\u0026rsquo;s assume for this demo that we are happy with the file we have created and want to keep the changes made.\nYou can now commit your changes to the repository by running:\ngit commit -m \u0026#34;created test.py\u0026#34; The -m \u0026quot;created test.py\u0026quot; is called a commit message and is required for committing changes to a repo. Always try to include an informative message that indicates what you changed or why you changed it.\nTo update these changes on the GitHub website, push your committed changes:\ngit push origin main Note - if git requests a username and password, please read the next section \u0026ldquo;Configuring Authentication\u0026rdquo;\nIn the above command, origin refers the directory we are going to push our changes. By default, git sets your origin to be the url you provided when you ran git clone. Next, main refers to the branch you would like to push your changes. Main is automatically set as the default branch for a new repository - if you see older tutorials, they may list master as the primary branch, just know these function as the same thing. Branches are useful for creating different versions or iterations of a project without having to over-write old editions.\nYou should now be able to see your new file as shown below.\nConfiguring Authentication When you push/pull to GitHub, you may be prompted for a username and passsword. GitHub uses personal access tokens to authenticate users - similar to how apple or google handle authentication with \u0026ldquo;app specific passwords\u0026rdquo;. To create a personal access token:\n Go to GitHub \u0026ndash;\u0026gt; Settings Select Developer Settings Under Personal access tokens, select Generate new token Give the token a short description Set the Expiration time Select the scope for the given token  I typically choose repo for personal projects   Click Generate token \u0026ndash;\u0026gt; do not close this page Back in your terminal, run the following:  # depending on your system, you will need to run either of these commands # this will save your access token the next time you are prompted for it git config --global credential.helper manager-core git config --global credential.help store Run your git push command again  When prompted, enter your username For password, copy / paste the personal access token we created in step 7  Since it\u0026rsquo;s a password, you will not see any text appear in your terminal but this is normal      If you would like to use SSH to connect to repositories, see my other post: Git SSH Integration \nTL;DR  Create new git repo git clone git add git commit git push  setup access token    Final Comments There are many more features included with git and GitHub that are not shown in this tutorial. Being efficient with git is an art of its own. For now, you should be able to create and add files to a new repository. Start playing around with making new projects and hosting them on GitHub; you will eventually find that you may need more functionality but this should at least give you a good starting point.\n","permalink":"https://kmclester.com/posts/github/first-git/","summary":"Create repository and make first commit","title":"Creating a GitHub Repo"},{"content":"You may be accustomed to using your Git project url (https) for cloning and pushing to your Git repo, however you can also use SSH. I\u0026rsquo;m not going to go into which method is better, I\u0026rsquo;ll just be showing you how it\u0026rsquo;s done.\nCreating SSH Key  First, we must check if an SSH key already exists. You can do so by running:  ssh-add -l If no key exists, run the following command:  # substituting email for the email you use with GitHub ssh-keygen -t rsa -b 4096 -C \u0026#34;kmcleste@uncc.edu\u0026#34; Press enter to accept the default file location Enter a Secure Passphrase Press Enter to complete key generation Display the contents of your Public Key  # this is the path for my default installation, yours may be different # refer to the path provided when creating your key cat ~/home/kyle/.ssh/id_rsa.pub Copy the contents of your Public Key  Add Key to GitHub  Login to your GitHub account  Click your avatar and choose Settings Select SSH and GPG Keys from the settings list Click New SSH Key Enter a descriptive title in the title field Paste your public key into the Key field Finish by clicking Add SSH Key  SSH in Action Now when you set your origin or clone/push/pull, you will use the ssh link provided by GitHub; which will look something like this:\ngit clone git@github.com:kmcleste/git-tutorial.git Assuming you set a passphrase in the previous steps, you will be prompted for this phrase everytime you try to clone/push/pull.\n","permalink":"https://kmclester.com/posts/github/git-ssh/","summary":"Secure git repo connection with SSH","title":"GitHub SSH"},{"content":"OCTIS GitHub \nOCTIS or \u0026ldquo;Comparing and Optimizing Topic Models is Simple\u0026rdquo; was created by a team in Italy to assist with training, analyzing, and comparing topic models (Terragni et al. 2021). They intend for OCTIS to be used by researchers to aid in comparing models of interest; which are scored using benchmark datasets and well-known evalutation metrics. Assuming wide adoption, it would make comparing research teams results' much easier as everyone would be using the same testing methodology.\nWhat is Topic Modeling? If you have never heard of or worked with topic modeling, have no fear; the concept is pretty intuitive. The general premise behind topic models are that they are statistical methods that aim to extract the hidden topics underlying a collection of documents. Said differently, they allow us to get a \u0026ldquo;birds eye view\u0026rdquo; of a documents content. For example, if we were performing topic modeling on the linked research paper, the model may return \u0026ldquo;octis framework optimize evaluation hyperparameter\u0026rdquo;. As I mentioned, this gives us an idea of what the document is about without having to read the entire paper.\nA Brief History An early version of topic modeling was originally described in 1998 (Papadimitriou et al. 1998). Another was created by Thomas Hofmann in 1999 called probabilistic latent semantic analysis or \u0026ldquo;PLSA\u0026rdquo; (Hofmann 1999). Shortly thereafter, Latent Dirichlet allocation (LDA) was created as a generalization of PLSA - this is generally accepted as the most common topic model currently in use (Blei, Ng, and Jordan 2003).\nLDA is an unsupervised approach that allows us to find latent or \u0026ldquo;hidden\u0026rdquo; themes in a collection of documents. This process assumes each document is a \u0026ldquo;bag of words\u0026rdquo; and that each word/document falls into one of k topics. We\u0026rsquo;re able to use the following probabilities: P(topic t | document d) and P(word w | topic t) to surmise the appropriate topic associated with each document. LDA also uses Bayesian principles in the form of generating prior predictive probabilities and applying Bayesian updating to iteratively calculate posterior probabilities - once some threshold is met, the algorithm returns the list of topics and associated words.\nAs I mentioned, LDA is one of the most popular options and is great for what it is but it experiences one major pitfall \u0026ndash; context. LDA and topic models as a whole began to fall out of favor with scientists around 2012 due to the introduction of neural based approaches (Ruder 2021). These approaches include word embeddings (word2vec, glove, etc), sequence-to-sequence models, attention (transform) models, and pre-trained language models (BERT, Huggingface, etc). A nueral based approach allows models to account for the context in which a word is spoken/written - they can alter their vector representation based on surrounding words, part of speech, etc.\nFortunately, topic models have recently recieved a neural \u0026ldquo;facelift\u0026rdquo; as well. Several new methods such as Neural LDA, Embedded Topic Models (ETM), and Contextualized Topic Models (CTM) have all been developed within the last two to five years (Terragni et al. 2021). The team behind OCTIS hope to combine both modern and traditional techniques into a unified framework - such that researchers can compare the accuracy of models against a standardized baseline. The intention is not to determine which model is the all-around king of models, rather, it is to test which model would be the best for a given scenario. Neural approaches are all the rave right now but occassionally it is wise to brush off the traditional methods as they may be faster, more efficient, or achieve 95% of the desired response with minimal effort. It is also a good idea to understand the old way of doing things so you can better appreciate what newer methods have to offer.\ntl;dr LDA is great; people think neural nets are cool; new isn\u0026rsquo;t always better but sometimes it is; OCTIS wants to make comparing them easier; models are just tools\nLearning is a Process OCTIS follows the general framework shown below. These pipelines are setup for ease of use but also repeatability. Understanding this workflow is key to being successful with OCTIS.\nPre-processing First, we import a raw dataset and pass it to the pre-processing pipeline. This pipeline can convert all text to lowercase, remove punctuation, lemmatization, remove stop words (a, and, the, etc.), remove unfrequent and most frequent words based on a given threshold, and remove documents with less words than some threshold value. It is important to remember that just because a utility is included, does not mean you have to use it. Not every document requires the aforementioned operations and it\u0026rsquo;s up to the researchers discression to determine the best course of action.\nOCTIS includes several tests datasets:\n   Dataset Domain # Docs Avg # words in docs # Unique words     20 News-groups Forum posts 16309 48 1612   BBC News News 2225 150 3106   M10 Scientific Papers 8355 6 1696   DBLP Scientific Papers 54595 5 1513    Topic Modeling OCTIS includes a variety of off-the-shelf topic models, including both classical and neural approaches. The included models are:\n Latent Dirichlet Allocation (LDA) Non-negative Matrix Factorization (NMF) Latent Semantic Analysis (LSI) Hierarchical Dirichlet Process (HDP) Neural LDA Product-of-Experts LDA (ProdLDA) Embedded Topic Models (ETM) Contexualized Topic Models (CTM)  Topic models are effectively a black-box. They take a dataset as input and a set of hyperparameters and return the top-t topic words, the document-topic distributions, and the topic-word distribution in a specified format.\nEvaluation metrics The evaluation metrics can be used in two ways:\n An objective which is targeted by the Bayesian Optimization strategy A metric in which to monitor the behavior of a topic model while the model is optimized on a different objective  Performance of the topic model can be evaluated using the following metrics:\n Topic coherence metrics Topic significance metrics Diversity metrics Classification metrics  OCTIS provides 10 evaluation metrics directly from their web dashboard and then 13 additional metrics can be accessed through the python library.\nHyper-parameter Optimization If any of the available hyper-parameters are selected to be optimized (for a given evaluation metric), the Bayesian Optimization engine explores the search space to determine the optimal settings. These optimal settings are based on a desired threshold set for the selected evaluation metric. The team behind OCTIS realized that the performance estimated by these metrics can be subject to noise, so they decided the objective function should be computed as the median of n-model runs, using the same hyper-paramter configuration.\nIn this case, Bayesian Optimization is a sequential model-based optimization strategy for black-box functions (topic models). The general idea is to use all of the model\u0026rsquo;s configurations evaluated so far to best approximate the value of the selected performance metric and then select a new promising configuration to evaluate (Terragni et al. 2021).\n\u0026ldquo;The approximation is provided by a probabilistic surrogate model, which describes the prior belief over the objective function using the observed configurations. The next configuration to evaluate is selected through the optimization of an acquisition function, which leverages the uncertainty in the posterior to guide the exploration.\u0026rdquo; (Terragni et al. 2021)\n OCTIS in Action LDA Example  # Import dependencies from octis.models.LDA import LDA from octis.dataset.dataset import Dataset from octis.evaluation_metrics.diversity_metrics import TopicDiversity from octis.evaluation_metrics.coherence_metrics import Coherence  # Define dataset dataset = Dataset() dataset.fetch_dataset(\u0026#34;20NewsGroup\u0026#34;)  # Create Model model = LDA(num_topics=20, alpha=0.1)  # Train the model using default partition choice output = model.train_model(dataset) print(*list(output.keys()), sep=\u0026#34;\\n\u0026#34;) # Print the output identifiers topic-word-matrix topics topic-document-matrix test-topic-document-matrix    # Return the generated topics [\u0026#39; \u0026#39;.join(x) for x in output[\u0026#39;topics\u0026#39;]] ['woman son church kill body wife people mother leave start', 'government state people law information group issue military make control', 'file image program version application include widget system window server', 'people make give sin day time man life love good', 'list print program port computer printer include work address color', 'people religion make thing belief time christian question point church', 'car good make price engine mile power buy water sell', 'encryption chip clipper key system government technology law year escrow', 'time phone people ground happen start make hear leave put', 'question drive monitor power system apple post newsgroup answer gay', 'game team win play year good player time season make', 'drive card disk run work system driver scsi make chip', 'drug test patient disease doctor medical study problem good card', 'make fire claim people evidence point reason post word case', 'window problem work mode run block bit switch button memory', 'armenian people turkish year genocide population jewish village greek war', 'key mail send number message post info call reply company', 'homosexual man sex homosexuality male sexual cap make pen show', 'gun law weapon people firearm car good death pay kill', 'space launch system cost mission satellite orbit solar make year']    # Initialize performance metric npmi = Coherence(texts=dataset.get_corpus(), topk=10, measure=\u0026#39;c_npmi\u0026#39;) # Initialize performance metric topic_diversity = TopicDiversity(topk=10)  # Retrieve metric scores topic_diversity_score = topic_diversity.score(output) print(f\u0026#39;Topic diversity: {str(topic_diversity_score)}\u0026#39;) npmi_score = npmi.score(output) print(f\u0026#39;Coherence: {str(npmi_score)}\u0026#39;) Topic diversity: 0.725   Coherence: 0.07167448455491789    NOTE: For a neural-based example, see the Google Colab  notebook provided by OCTIS.\n Sources Blei, David M, Andrew Y Ng, and Michael I Jordan. 2003. \u0026ldquo;Latent Dirichlet Allocation.\u0026rdquo; Journal of Machine Learning Research 3 (Jan): 993\u0026ndash;1022.\n Hofmann, Thomas. 1999. \u0026ldquo;Probabilistic Latent Semantic Indexing.\u0026rdquo; In Proceedings of the 22nd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, 50\u0026ndash;57. SIGIR \u0026lsquo;99. New York, NY, USA: Association for Computing Machinery. https://doi.org/10.1145/312624.312649 .\n Papadimitriou, Christos H., Hisao Tamaki, Prabhakar Raghavan, and Santosh Vempala. 1998. \u0026ldquo;Latent Semantic Indexing: A Probabilistic Analysis.\u0026rdquo; In Proceedings of the Seventeenth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems, 159\u0026ndash;68. PODS \u0026lsquo;98. New York, NY, USA: Association for Computing Machinery. https://doi.org/10.1145/275487.275505 .\n Ruder, Sebastian. 2021. \u0026ldquo;A Review of the Recent History of Natural Language Processing.\u0026rdquo; Sebastian Ruder, Sebastian Ruder.\n Terragni, Silvia, Elisabetta Fersini, Bruno Giovanni Galuzzi, Pietro Tropeano, and Antonio Candelieri. 2021. \u0026ldquo;OCTIS: Comparing and Optimizing Topic Models Is Simple!\u0026rdquo; In Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: System Demonstrations, 263\u0026ndash;70. Online: Association for Computational Linguistics. https://doi.org/10.18653/v1/2021.eacl-demos.31 .\n  ","permalink":"https://kmclester.com/posts/octis/octis/","summary":"Optimizing and Comparing Topic Models is Simple!","title":"Intro to OCTIS"},{"content":"Head to the Get Started  page on Quarto\u0026rsquo;s website and download the latest version of Quarto for your operating system. You can verify your installation is working by running this command:\nquarto check install Hugo Integration Once you have verified your installation, you can head over to your project folder. Start by editing your site configuration file (config.toml) by adding the following parameters:\nignoreFiles = [ \u0026#34;\\\\.qmd$\u0026#34;, \u0026#34;\\\\.ipynb$\u0026#34; ] [markup.goldmark.renderer] unsafe = true Creating Quarto documents   Create a directiry within content that will hold your Quarto article\n  Add your article as a .qmd file. So you might name it something like \u0026ldquo;tutorial.qmd\u0026rdquo;. This will create \u0026ldquo;tutorial.md\u0026rdquo; when rendered which is then displayed by Hugo.\n  Add your Hugo front matter  and then specify format: hugo and any other Quarto options. Here\u0026rsquo;s an example front matter:\n  --- title: How to Quarto date: \u0026#34;2022-02-08\u0026#34; format: hugo author: Kyle McLester description: Adding Quarto to Existing Hugo Project --- To render Quarto markdown to regular markdown, use the following:  quarto render $PATH_TO_FILE/$FILE.qmd ","permalink":"https://kmclester.com/posts/quarto/how-to-quarto/","summary":"Integrate Quarto to your Hugo website","title":"How to Quarto"},{"content":"","permalink":"https://kmclester.com/posts/rasa/slack/","summary":"üöß UNDER CONSTRUCTION","title":"Connecting Rasa to Slack Application"},{"content":"","permalink":"https://kmclester.com/posts/jina/first-jina/","summary":"üöß UNDER CONSTRUCTION - Using Jina.ai to create a basic multi-modal neural search application","title":"Getting Started with Neural Search"},{"content":"","permalink":"https://kmclester.com/posts/nlp/attention-models/","summary":"üöß UNDER CONSTRUCTION","title":"Understanding Attention Models"},{"content":"","permalink":"https://kmclester.com/posts/nlp/word-embeddings/","summary":"üöß UNDER CONSTRUCTION - A bried history and explanation of word embeddings, their application, and alternatives","title":"What are Word Embeddings?"},{"content":"  form{ background: rgba(27,31,34,0.80); width: 640px; margin: 50px auto; max-width: 97%; border-radius: 4px; padding: 55px 30px; } form .title h2{ letter-spacing: 6px; display: inline-block; padding: 8px; margin-bottom: 32px; color: white; } form{ border: 1px solid white; } form .half{ display: flex; justify-content: space-between; } form .half .item{ display: flex; flex-direction: column; margin-bottom: 24px; width: 48%; color: white; } .full{ color: white; } form label{ display: block; font-size: 13px; letter-spacing: 3.5px; margin-bottom: 16px; } form .half .item input{ border-radius: 4px; border: 1px solid white; outline: 0; padding: 16px; width: 100%; height: 44px; background: transparent; font-size: 17px; } form .full{ margin-bottom: 24px; } form .full textarea{ background: transparent; border-radius: 4px; border: 1px solid white; outline: 0; padding: 12px 16px; width: 100%; height: 200px; font-size: 17px; } form .action{ margin-bottom: 32px; } form .action input{ background: transparent; border-radius: 4px; border: 1px solid white; cursor: pointer; font-size: 13px; font-weight: 600; height: 44px; letter-spacing: 3px; outline: 0; padding: 0 20px 0 22px; margin-right: 10px; } form .action input[type=\"submit\"]{ background: white; color: black; } form .half .item input:focus, form .full textarea:focus, form .action input[type=\"reset\"]:hover{ background: rgba(255,255,255,0.075); } form .action input[type=\"reset\"]{ color: white; } @media (max-width: 480px){ form .half{ flex-direction: column; } form .half .item{ width: 100%; } form .action{ display: flex; flex-direction: column; } form .action input{ margin-bottom: 10px; width: 100%; } } .hidden{ visibility: hidden; }   Let's Connect!  NAME  EMAIL   MESSAGE     Don't fill this out if you're human:    ","permalink":"https://kmclester.com/contact/","summary":"Let\u0026rsquo;s Connect!","title":"Contact"}]